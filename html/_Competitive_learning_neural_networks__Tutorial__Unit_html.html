<h3>CLFFNN - An Introduction</h3>
<p>In this experiment we consider pattern recognition tasks that a network of the type shown in Fig. 1 below can perform. The network consists of an input layer of linear units. The output of each of these units is given to the units in the second layer (output layer) with (adjustable) feed forward weights. The output functions of the units in the second layer are either linear or nonlinear depending on the task for which the network is to be designed. The output of each unit in the second layer is fed back to itself in a self-excitatory manner and to the other units in the layer in an excitatory or inhibitory manner depending on the task. Generally the weights on the connections in the feedback layer are nonadaptive or fixed. Such a combination of feed forward and feedback connection between layers results in some kind of competition among the activations of the units in the output layer, and hence such networks are called competitive learning neural networks. Different choices of the output functions and interconnections in the feedback layer of the network can be used to perform different pattern recognition tasks. For example, if the weights loading to the unit with the largest output for a given input are adjusted, the resulting network performs pattern clustering or grouping, provided the feedback connections in the output layer are all inhibitory. The unit with largest output for a given input is called winner, and the learning law is called winner-take-all learning.</p>
<p></p>
<table width="750">
<tbody>
<tr>
<td height="450"><img src="http://cse22-iiith.vlabs.ac.in/exp7/images/CLNN.png" style="height: 90%; width: 90%;" /></td>
</tr>
</tbody>
<caption align="bottom"><b>Figure 1: </b><em>Basic competitive learning network.</em></caption></table>
<h3>Analysis of feature mapping network</h3>
<p>There are situations where it is difficult to group the input patterns into distinct groups. The patterns may form a continuum in feature space, and it is this kind of information that may be needed in some applications. For example, it may be of interest to know how close a given input is to some of the other patterns for which the feed forward path has already been trained. In other words, it is of interest to have some order in the output of a unit in the feedback layer in relation to the outputs of its neighboring units. This is called feature mapping. The network that achieves this is called feature mapping network.</p>
<p>A feature mapping network is also a competitive learning network with nonlinear output functions for units in the feedback layer, as in the networks used for pattern clustering. But the main distinction is in the geometrical arrangement of the output units, and the significance attached to the neighboring units during training. Thus, feature mapping could also be viewed as topology preserving map from the space of possible input values to a line or a plane of the output units [Kohonen, 1982b; Kohonen, 1989.] The inputs to a feature mapping network could be N-dimensional patterns, applied one at a time, and the network is to be trained to map the similarities of the input patterns in the weights leading to the neighbouring units. Another type of input is shown in Figure 2, where the inputs are arranged in a 2-D array so that the array represents the input pattern space as in the case of a textured image. At any given time only a few of the input units may be turned on, and hence only the corresponding links are activated.</p>
<p></p>
<table width="800">
<tbody>
<tr>
<td height="500"><img src="http://cse22-iiith.vlabs.ac.in/exp7/images/FeatureMapping.png" style="height: 90%; width: 90%;" /></td>
</tr>
</tbody>
<caption align="bottom"><b>Figure 2: </b><em>Illustration of SOM networks.</em></caption></table>
<p>The self-organization network is trained as follows: The weights are set to random initial values. When an input vector \(x\) is applied, the winning unit \(k\) in the output layer is identified such that</p>
<p>||<b>x</b> - <b>w</b>\(_k\) || \(\le\) ||<b>x</b> - <b>w</b>\(_i\) || \(\forall\) \(i \qquad(1)\)</p>
<p>where <b>w</b>\(_i\) is the weight vector leading to the unit \(i\) in the output layer.</p>
<p>The weights associated with the winning unit k and its neighbouring units m, identified by a neighbourhood function \( \lambda(k, m) \), are updated using the expression</p>
<p>\( \Delta{w_m} = \eta{*}\lambda{(k,m)(x-w_m)} \qquad(2)\)</p>
<p>The neighbourhood function \( \lambda(k, m)~\) is maximum for \(m = k.~\) A suitable choice for \( \lambda(k, m)~\) is a Gaussian function of the type</p>
<p>\( \lambda(k,m) = ({1/}\sqrt{2\pi}\sigma) * exp(-||\)<b>r</b>\(_k\)-<b>r</b>\(_m||)^2/2\sigma^2 \qquad(3)\)</p>
<p>where <b>r</b>\(_k \) refers to the position of the \(k^{th}\) unit in the 2-D plane of the output units. The width of the Gaussian function, described by \( \sigma\), is gradually decreased to reduce the neighbourhood region in successive iterations of the training process. Even the learning rate parameter \(\eta\) can be changed as a function of time during the training phase. The weights are renormalized each time after the update.</p>
<p></p>
<h3>Following is an algorithm for implementing the self-organizing feature map learning.</h3>
<ol><ol><ol>
<li>
<p>Initialize the weights from \(M\) inputs to the \(N\) output units to small random values. Initialize the size of the neighbourhood region \( R(0)\).</p>
</li>
<li>
<p>Present a new input <b><i>a</i></b>.</p>
</li>
<li>
<p>Compute the distance \(d_i\) between the input and the weight on each output unit \(i\) as \( d_i = \sum\limits_{j=1}^M [a_j(t)-w_{ij}(t)]^2 ,\) \(for\) \(i = 1,2.. N,~\) where \(a_i(t)\) is the input to the \(j^{th}\) input unit at time \(t\) and \(w_{ij}\) is the weight on the \(j^{th}\) input unit to the \(i^{th}\) output unit.</p>
</li>
<li>
<p>Select the output unit \(k\) with minimum distance \( k =\) index of \([\min(d_i)]\) over \(i\)</p>
</li>
<li>
<p>Update weight to node \(k\) and its neighbours \(w_{ij}(t+1) = w_{ij}(t) + \eta(t)(a_j(t)- w_{ij}(t))\) for \( i\) \( \epsilon\) \(R_k(t)\) \(and\) \(j=1,2...M, ~ \) where \(\eta(t)\) is the learning rate parameter \( (0 \lt \eta(t) \lt 1) \) that decreases with time.</p>
</li>
<li>
<p>Repeat steps 2 to 5 for all inputs several times</p>
</li>
</ol></ol></ol>